{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Latent_Dirichlet_Allocation import normalization_string, create_stop_word\n",
    "from Latent_Dirichlet_Allocation import LDA_In_EM, LDA_In_VB, LDA_In_CGS\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet1 = pd.read_csv('csv_data/20250127_tweet_data.csv')\n",
    "df_tweet1['text'] = df_tweet1['text'].str.removeprefix('[').str.removesuffix(']')\n",
    "df_tweet2 = pd.read_csv('csv_data/20250304_tweet_data.csv')\n",
    "df_tweet2['text'] = df_tweet2['text'].str.removeprefix('[').str.removesuffix(']')\n",
    "df_tweet = pd.concat([df_tweet1, df_tweet2]).reset_index(drop=True)\n",
    "df_tweet = df_tweet[['text']]\n",
    "df_tweet = normalization_string(df_tweet, 'text')\n",
    "df_tweet = df_tweet.drop_duplicates(subset='text', keep='first', ignore_index=True)\n",
    "\n",
    "df_tweet.to_parquet('./parquet_data/20250227_tweet_normalized.parquet')\n",
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json_data/custom_stopwords_en.json', 'r') as f:\n",
    "\tstop_word_en = json.load(f)\n",
    "\tstop_word_en = stop_word_en['stopwords']\n",
    "\n",
    "with open('json_data/custom_stopwords_ja.json', 'r') as f:\n",
    "\tstop_word_ja = json.load(f)\n",
    "\tstop_word_ja = stop_word_ja['stopwords']\n",
    "\n",
    "stop_word_digit1 = [str(idx) for idx in range(10000)]\n",
    "stop_word_digit2 = [str(idx).zfill(2) for idx in range(100)]\n",
    "stop_word_digit3 = [str(idx).zfill(3) for idx in range(1000)]\n",
    "stop_word_digit4 = [str(idx).zfill(4) for idx in range(10000)]\n",
    "stop_word_alpha  = [chr(idx) for idx in range(ord('a'), ord('z')+1)]\n",
    "stop_word_ALPHA  = [chr(idx) for idx in range(ord('A'), ord('Z')+1)]\n",
    "stop_word_hira   = [chr(idx) for idx in range(ord('あ'), ord('ん')+1)]\n",
    "stop_word_kata   = [chr(idx) for idx in range(ord('ァ'), ord('ン')+1)]\n",
    "stop_word_kanji  = ['一', '二', '三', '四', '五', '六', '七', '八', '九', '十']\n",
    "stop_word_greece = [chr(idx) for idx in range(ord('α'), ord('ω')+1)]\n",
    "stop_word_GREECE = [chr(idx) for idx in range(ord('Α'), ord('Ω')+1)]\n",
    "stop_word_cyril  = [chr(idx) for idx in range(ord('а'), ord('я')+1)]\n",
    "stop_word_CYRIL  = [chr(idx) for idx in range(ord('А'), ord('Я')+1)]\n",
    "stop_word_symbol = ['・', '゚', '!', '。', \"'\", '_', '%']\n",
    "stop_word_custom = stop_word_digit1 + stop_word_digit2 + stop_word_digit3 + stop_word_digit4\\\n",
    "    \t\t\t\t+ stop_word_alpha + stop_word_ALPHA\\\n",
    "            \t\t+ stop_word_hira  + stop_word_kata + stop_word_kanji\\\n",
    "                  \t+ stop_word_greece + stop_word_GREECE\\\n",
    "                    + stop_word_cyril + stop_word_CYRIL\\\n",
    "                    + stop_word_symbol\n",
    "\n",
    "# stop_word = create_stop_word(df_tweet, 'text', stop_word_en + stop_word_ja, 5)\n",
    "stop_word = create_stop_word(df_tweet, 'text', stop_word_en + stop_word_ja + stop_word_custom, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LDA_In_EM(df_tweet, stop_word=stop_word, topic_num=10)\n",
    "model.fit()\n",
    "\n",
    "print(f'topic of EM algorithm: finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_θ, pd_Φ = model.stats_info()\n",
    "pd_θ.to_parquet('./parquet_data/20250227_tweet_EM_θ.parquet')\n",
    "pd_Φ.to_parquet('./parquet_data/20250227_tweet_EM_Φ.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LDA_In_VB(df_tweet, stop_word=stop_word, topic_num=10)\n",
    "model.fit()\n",
    "\n",
    "print(f'topic of Variational Bayes algorithm: finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_θ, pd_Φ = model.stats_info()\n",
    "pd_θ.to_parquet('./parquet_data/20250227_tweet_VB_θ.parquet')\n",
    "pd_Φ.to_parquet('./parquet_data/20250227_tweet_VB_Φ.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LDA_In_CGS(df_tweet, stop_word=stop_word, topic_num=10)\n",
    "model.fit()\n",
    "\n",
    "print(f'topic of Variational Bayes algorithm: finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_θ, pd_Φ = model.stats_info()\n",
    "pd_θ.to_parquet('./parquet_data/20250227_tweet_CGS_θ.parquet')\n",
    "pd_Φ.to_parquet('./parquet_data/20250227_tweet_CGS_Φ.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
